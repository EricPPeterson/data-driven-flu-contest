{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from numpy import where\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_set_features.csv')\n",
    "test['label'] = 'test'\n",
    "train = pd.read_csv('training_set_features.csv')\n",
    "train['label'] = 'train'\n",
    "labels = pd.read_csv('training_set_labels.csv')\n",
    "h1n1 = labels['h1n1_vaccine']\n",
    "seasonal = labels['seasonal_vaccine']\n",
    "combine = pd.concat([train, test], axis = 0)\n",
    "ID = test['respondent_id']\n",
    "combine = combine.drop(['respondent_id'], axis = 1)\n",
    "full_train = pd.concat([labels, train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_cols = combine.columns\n",
    "labels_cols = labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column names\n",
    "print(combine_cols)\n",
    "print(labels_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of the dataframes\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(labels.shape)\n",
    "print(combine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the response variables\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#26707 total rows\n",
    "#21.2% got h1n1_vaccine\n",
    "#46.6% got seasonal vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = (combine.isnull().sum()/len(combine))\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:40]\n",
    "missing_data = pd.DataFrame({'Missing Ratio':all_data_na})\n",
    "missing_data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like employment occupation and employment industry is not code for not in work force where blank.\n",
    "combine['employment_industry'] = combine['employment_industry'].fillna('abcde')\n",
    "combine['employment_occupation'] = combine['employment_occupation'].fillna('fghij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = combine.select_dtypes('object').columns\n",
    "print(label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process columns, apply LabelEncoder to categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in label_enc:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(combine[c].values)) \n",
    "    combine[c] = lbl.transform(list(combine[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(combine.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = (combine.isnull().sum()/len(combine))\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:40]\n",
    "missing_data = pd.DataFrame({'Missing Ratio':all_data_na})\n",
    "missing_data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=all_data_na.index, y=all_data_na)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anything with under 2% missing, just input the mode\n",
    "cols = ('opinion_seas_sick_from_vacc', 'opinion_seas_risk' , 'opinion_seas_vacc_effective',\n",
    "        'opinion_h1n1_vacc_effective','opinion_h1n1_sick_from_vacc', 'opinion_h1n1_risk', 'household_children',\n",
    "        'household_adults', 'behavioral_avoidance', 'behavioral_touch_face', 'h1n1_knowledge', 'h1n1_concern',\n",
    "        'behavioral_outside_home', 'behavioral_large_gatherings', 'behavioral_antiviral_meds', 'behavioral_wash_hands',\n",
    "        'behavioral_face_mask')\n",
    "\n",
    "for c in cols:\n",
    "    combine[c] = combine[c].fillna(combine[c].mode()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = (combine.isnull().sum()/len(combine))\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:40]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=all_data_na.index, y=all_data_na)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = combine.corr()\n",
    "plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['doctor_recc_seasonal', 'doctor_recc_h1n1', 'chronic_med_condition', 'child_under_6_months',\n",
    "                           'health_worker', 'health_insurance']\n",
    "before = []\n",
    "for c in cols:\n",
    "    w = len(combine[c][combine[c]==1])\n",
    "    wo = len(combine[c][combine[c]==0])\n",
    "    pct_w = w / (w + wo)\n",
    "    before.append(pct_w)\n",
    "    print('percentage with', c, pct_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model to fill values\n",
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "roc = []\n",
    "\n",
    "for index, value in enumerate(cols):\n",
    "    cols = ['doctor_recc_seasonal', 'doctor_recc_h1n1', 'chronic_med_condition', 'child_under_6_months',\n",
    "                           'health_worker', 'health_insurance']\n",
    "    \n",
    "    a = cols[index]\n",
    "    cols.pop(index)\n",
    "    X = combine.drop(columns = cols)\n",
    "    W = X[X[a].notnull()]\n",
    "    y = W[a]\n",
    "    X = X.drop([a], axis = 1)\n",
    "    W = W.drop([a], axis = 1)\n",
    "    \n",
    "    oversample = SMOTE()\n",
    "    W, y = oversample.fit_resample(W,y)\n",
    "    \n",
    "    #model = DecisionTreeClassifier()\n",
    "    model = GradientBoostingClassifier()\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, W, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    print('mean roc', a, mean(scores))\n",
    "    #fit model\n",
    "    model.fit(W,y)\n",
    "    \n",
    "    #make predictions\n",
    "    combine['preds'] = model.predict(X)\n",
    "    combine[a] = np.where(combine[a].isnull(), \n",
    "                                           combine['preds'], combine[a])\n",
    "    combine = combine.drop(['preds'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all NAs are gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create baseline model with logistic regression\n",
    "train = combine[combine['label'] == 1]\n",
    "test = combine[combine['label'] == 0]\n",
    "train = train.drop(['label'], axis = 1)\n",
    "test = test.drop(['label'], axis = 1)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare ensemble to each baseline classifier\n",
    "\n",
    "  \n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression()))\n",
    "    #level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('boost', GradientBoostingClassifier()))\n",
    "    #level0.append(('bayes', GaussianNB()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    #models['knn'] = KNeighborsClassifier()\n",
    "    models['boost'] = GradientBoostingClassifier()\n",
    "    #models['bayes'] = GaussianNB()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "#set data\n",
    "X,y = (train, seasonal)\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data\n",
    "X = train\n",
    "y = seasonal\n",
    "y = h1n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the base models\n",
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression()))\n",
    "level0.append(('knn', KNeighborsClassifier()))\n",
    "level0.append(('boost', GradientBoostingClassifier()))\n",
    "level0.append(('bayes', GaussianNB()))\n",
    "# define meta learner model\n",
    "level1 = LogisticRegression()\n",
    "# define the stacking ensemble\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "# fit the model on all available data\n",
    "model.fit(X, y)\n",
    "# make a prediction for one example\n",
    "yhat = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_h1n1_final = pd.DataFrame(yhat, columns = ['first_class', 'second_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_seasonal_final = pd.DataFrame(yhat, columns = ['first_class', 'second_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.concat([ID, y_pred_h1n1_final['second_class'],y_pred_seasonal_final['second_class']], axis = 1)\n",
    "response.columns = ['respondent_id','h1n1_vaccine', 'seasonal_vaccine']\n",
    "response.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.8367\n",
    "#325 out of 1911 top 17%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
